import numpy as np
import matplotlib.pyplot as plt
from sklearn.feature_selection import mutual_info_regression
from sklearn.linear_model import Ridge
from sklearn.model_selection import KFold
from sklearn.metrics import r2_score
import time

# ==========================================
# 1. PARAM√àTRES DE RE-SIMULATION V8.11.1
# ==========================================
HOTSPOTS = [(3, 3, 10.0, 0.0), (12, 12, 8.0, np.pi/2)]
SPIKE_PROB_FAST = 0.12
SPIKE_PROB_SLOW = 0.02
T = 1000 # 1000 steps pour garantir la convergence du Machine Learning

print("üî¨ Chargement du Champion V8.11.1...")
try:
    data = np.load("final_population_v8_11.npz", allow_pickle=True)
    champ = data["population"][0] # CORRECTION DU BUG .item()
except FileNotFoundError:
    print("‚ùå Fichier 'final_population_v8_11.npz' introuvable.")
    exit()

theta = champ["theta"]
tau = champ["tau_matrix"]
nx, ny = tau.shape

XS = np.arange(nx)[:, None]
YS = np.arange(ny)[None, :]

# ==========================================
# 2. G√âN√âRATION DES S√âRIES TEMPORELLES
# ==========================================
print(f"üåä Simulation de {T} cycles cognitifs...")
hs = np.zeros((T, nx, ny))
envs = np.zeros((T, nx, ny))

h = np.zeros_like(theta)
np.random.seed(42) # Seed fixe pour la consistance de l'analyse
for t in range(1, T + 1):
    env_field = np.zeros_like(theta)
    fast_comp = (1.0 if np.random.rand() < SPIKE_PROB_FAST else 0.1) * np.sin(t / 8.0)
    slow_comp = (1.0 if np.random.rand() < SPIKE_PROB_SLOW else 0.1) * np.sin(t / 200.0)
    for (x, y, amp, phase) in HOTSPOTS:
        dist2 = (XS - x)**2 + (YS - y)**2
        env_field += amp * np.exp(-dist2 / 9.0) * (fast_comp + slow_comp + 0.2 * np.sin(t/10.0 + phase))
    env_field += 0.3 * np.sin(t/100.0)
    
    h = tau * h + (1.0 - tau) * env_field
    hs[t-1] = h
    envs[t-1] = env_field

# ==========================================
# 3. ANALYSE A : INFORMATION MUTUELLE PR√âDICTIVE (LAG)
# ==========================================
print("‚è±Ô∏è Calcul de l'Information Mutuelle Pr√©dictive (Lags de 0 √† 50)...")
lags = np.arange(0, 51, 5) # On teste l'anticipation jusqu'√† 50 steps dans le futur
mi_lag = np.zeros((len(lags), nx, ny))

start_time = time.time()
for li, lag in enumerate(lags):
    source = hs if lag == 0 else hs[:-lag]
    target = envs if lag == 0 else envs[lag:]
        
    for i in range(nx):
        for j in range(ny):
            x = source[:, i, j].reshape(-1, 1)
            y = target[:, i, j].ravel()
            try:
                mi = mutual_info_regression(x, y, random_state=0)
                mi_lag[li, i, j] = mi[0]
            except Exception:
                mi_lag[li, i, j] = 0.0
print(f"‚úÖ MI calcul√©e en {time.time() - start_time:.1f} secondes.")

# Segmentation des neurones par leur taux de m√©moire (Tau)
tau_flat = tau.flatten()
quantiles = np.quantile(tau_flat, [0, 0.25, 0.5, 0.75, 1.0])
# Anti-crash si la variance de tau est trop faible
if len(np.unique(quantiles)) < 5:
    quantiles = np.linspace(tau_flat.min(), tau_flat.max(), 5)
    
group_idx = np.clip(np.digitize(tau_flat, quantiles) - 1, 0, 3)

mean_mi_by_group = np.zeros((len(lags), 4))
for li in range(len(lags)):
    mi_flat = mi_lag[li].flatten()
    for g in range(4):
        mask = (group_idx == g)
        if np.any(mask):
            mean_mi_by_group[li, g] = mi_flat[mask].mean()

# ==========================================
# 4. ANALYSE B : D√âCODAGE LIN√âAIRE (RIDGE) DU FUTUR
# ==========================================
LAG_RIDGE = 10
print(f"üîÆ Test de lecture dans les pens√©es (D√©codage Ridge pour t+{LAG_RIDGE})...")

X = hs[:-LAG_RIDGE].reshape(-1, nx * ny) # L'√©tat total du cerveau (Features)
r2_map = np.zeros((nx, ny))

kf = KFold(n_splits=3, shuffle=True, random_state=0)

for i in range(nx):
    for j in range(ny):
        y_loc = envs[LAG_RIDGE:, i, j] # Ce qu'on essaie de pr√©dire (Target)
        r2s = []
        for train_idx, test_idx in kf.split(X):
            model = Ridge(alpha=1.0)
            model.fit(X[train_idx], y_loc[train_idx])
            ypred = model.predict(X[test_idx])
            r2s.append(r2_score(y_loc[test_idx], ypred))
        r2_map[i, j] = np.mean(r2s)
print("‚úÖ D√©codage termin√©.")

# ==========================================
# 5. AFFICHAGE DES R√âSULTATS
# ==========================================
plt.figure(figsize=(16, 10))

# 1. Anatomie
plt.subplot(2, 2, 1)
plt.title("Anatomie : Matrice Tau (M√©moire)")
im0 = plt.imshow(tau, cmap="magma")
plt.colorbar(im0)
plt.contour(tau, levels=[np.percentile(tau, 75)], colors='cyan', linewidths=1) # Surligne le top 25% (Les Cores)

# 2. Performance de D√©codage (R¬≤)
plt.subplot(2, 2, 2)
plt.title(f"Pouvoir Pr√©dictif (R¬≤ du Cortex vers env local √† t+{LAG_RIDGE})")
im1 = plt.imshow(r2_map, cmap="inferno", vmin=0)
plt.colorbar(im1)

# 3. Courbes de MI Pr√©dictive par groupe
plt.subplot(2, 2, 3)
plt.title("Capacit√© d'Anticipation par type de Neurone (MI vs Lag)")
labels = ["Senseurs rapides", "Senseurs interm√©diaires", "M√©moire courte", "Cores (M√©moire longue)"]
colors = ["blue", "green", "orange", "red"]
for g in range(4):
    plt.plot(lags, mean_mi_by_group[:, g], label=labels[g], color=colors[g], linewidth=2, marker='o')
plt.xlabel("D√©calage temporel (Lag dans le futur)")
plt.ylabel("Information Mutuelle (Bits)")
plt.legend()
plt.grid(True, alpha=0.3)

# 4. Scatter Plot (Tau vs D√©codabilit√©)
plt.subplot(2, 2, 4)
plt.title("Corr√©lation Anatomie vs Capacit√© de Pr√©diction")
plt.scatter(tau.flatten(), r2_map.flatten(), s=20, alpha=0.7, c=tau.flatten(), cmap="magma", edgecolors="black")
plt.xlabel("Valeur de Tau (M√©moire locale)")
plt.ylabel(f"R¬≤ Score (Pr√©diction √† t+{LAG_RIDGE})")
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()